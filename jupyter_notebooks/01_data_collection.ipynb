{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part of CRISP-DM **Data Understanding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and save as raw data\n",
        "* Inspect the data and save it under outputs/datasets/collection.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file - the authentication token.\n",
        "* Raw downloaded data file\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate and save datasets:\n",
        "    * outputs/dataset/collection/house_price_records.csv\n",
        "    * outputs/dataset/collection/inherited_houses.csv\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* The first dataset in the outputs above is the data used to build our machine learning model(s). The second file consists of the inherited houses whose prices our client wants to predict.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install python packages in the notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip3 install -r /workspace/heritage-housing-issues//requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Fetch raw data from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To collect the data for our project, we will be using the Kaggle API. First, we need to install the Kaggle package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip3 install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To access the Kaggle API, we need to have an authentication token available in our workspace directory. This token is in the form of a file named 'kaggle.json'. If you don't have this file available, you can create one by following these steps:\n",
        "\n",
        "1. Log in to your existing Kaggle account or create a new one.\n",
        "2. Click on your user profile picture, then on “Settings” from the dropdown menu.\n",
        "3. Scroll down to the section called API.\n",
        "4. Click Expire API Token to remove any previous tokens.\n",
        "5. Click Create New API Token to generate a fresh authentication token and download the kaggle.json file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once you have the kaggle.json file, transfer it to your working directory and make sure it is named correctly. Then, run the following code to make the token recognized in the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset we will be using is located at the following URL: https://www.kaggle.com/datasets/codeinstitute/housing-prices-data. We can define the Kaggle path and destination folder as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/housing-prices-data\"\n",
        "DestinationFolder = \"inputs/datasets/raw\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then download the data using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After downloading the data, we can unzip the file and delete the zip file and kaggle.json file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! unzip {DestinationFolder}/*.zip -d {DestinationFolder} \\\n",
        "  && rm {DestinationFolder}/*.zip \\\n",
        "  && rm kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Load and Inspect Kaggle Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Load the Kaggle data using pandas.\n",
        "* Import the pandas library and load the dataset as a pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* View the first few rows of the data.\n",
        "* Get a summary of the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()\n",
        "df.info(max_cols=24)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Identify columns with missing values.\n",
        "* Check for duplicate rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()\n",
        "df[df.duplicated(subset=None)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Check each column for unique values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in df:\n",
        "    if df[col].dtypes == 'object':\n",
        "        print(col, '-', df[col].unique())\n",
        "    elif df[col].unique().size < 11:\n",
        "        print(col, '-', df[col].unique().size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our preliminary assessment of the data reveals:\n",
        "\n",
        "* The dataset contains 1460 rows and 24 columns.\n",
        "* The columns have a mix of data types, including integers, floats, and objects.\n",
        "* Several columns have missing values, which will require further attention.\n",
        "* Some columns appear to be categorical, based on the small number of unique values.\n",
        "\n",
        "We'll need to investigate these findings further and perform additional data cleaning and preprocessing in the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as they support your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Save the cleaned dataset to a local folder.\n",
        "* Push the dataset to the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/collection') # create a folder for the data output\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "df.to_csv(f\"outputs/datasets/collection/house_prices.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By saving the dataset to a local folder and pushing it to the repository, we ensure that our data is properly organized and easily accessible for further analysis and processing.\n",
        "\n",
        "Note: This completes the current Notebook. The cell outputs can now be cleared, and changes to the workspace can be pushed to the GitHub repository."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
