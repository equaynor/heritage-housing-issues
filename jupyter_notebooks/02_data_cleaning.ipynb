{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part of CRISP-DM **Data Understanding** and **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Data Exploration using ProfileReport\n",
        "* Correlation and PPS Analysis\n",
        "* Detailed evaluation of missing data\n",
        "* Imputing strategies for missing data\n",
        "* Split Train and Test Sets\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/house_prices.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Cleaned Train and Test sets, saved under outputs/datasets/cleaned\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"outputs/datasets/collection/house_prices.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pandas Profiling Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we want to get familiar with the dataset. Using ProfileReport we can look at the variable types, distribution, missing data levels, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df, minimal=True)\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The report shows that of the 24 variables, 4 are text values.\n",
        "* Closer inspection shows that 2 of the numerical valiables ['OverallCond', 'OverallQual'] represent categories as well, making a total of 5 categorical variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[abs(df) < threshold] = True\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                    linewidth=0.5\n",
        "                    )\n",
        "        axes.set_yticklabels(df.columns, rotation=0)\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[abs(df) < threshold] = True\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                         linewidth=0.05, linecolor='grey')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "    df_corr_spearman = df.corr(method=\"spearman\")\n",
        "    df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "    pps_matrix_raw = pps.matrix(df)\n",
        "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "    print(pps_score_stats.round(3))\n",
        "\n",
        "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                      figsize=(20, 12), font_annot=8):\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "    print(\"It evaluates monotonic relationship \\n\")\n",
        "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman,\n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.4, PPS_Threshold = 0.2,\n",
        "                  figsize=(12,10), font_annot = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assessing Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since there appears to be multiple variables with missing data, we filter them out and take a closer look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "df[vars_with_missing_data].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code from walkthrough project 02, data cleaning notebook\n",
        "\n",
        "if vars_with_missing_data:\n",
        "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
        "    profile.to_notebook_iframe()\n",
        "else:\n",
        "    print(\"There are no variables with missing data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* 9 of 24 variables have missing values, which amounts to 37.5%.\n",
        "* 2 variables have more than 50% zeros.\n",
        "* Roughly 26% of cells are missing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use another more concise way to inspect the missing data by using a custom function called EvaluateMissingData.\n",
        "For each variable it evaluates the number of missing data values and the overall percentage of missing data and returns a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code from walkthrough project 02, data cleaning notebook\n",
        "\n",
        "def EvaluateMissingData(df):\n",
        "    missing_data_absolute = df.isnull().sum()\n",
        "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
        "    df_missing_data = (pd.DataFrame(\n",
        "        data={\"RowsWithMissingData\": missing_data_absolute,\n",
        "              \"PercentageOfDataset\": missing_data_percentage,\n",
        "              \"DataType\": df.dtypes}\n",
        "    )\n",
        "                       .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
        "                       .query(\"PercentageOfDataset > 0\")\n",
        "                      )\n",
        "    return df_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* 2 variables ['EnclosedPorch', 'WoodDeckSF'] have more than 85% missing values each.\n",
        "* These variables may warrant dropping them because they will have little or no predictive power."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* **Drop:** The dataset contains excessive missing values in the 'EnclosedPorch' and 'WoodDeckSF' columns, with over 80% of the data missing. These variables may not be useful for predictive modeling due to the lack of significant variation across houses.\n",
        "* **Mean Imputation:** Suitable for 'LotFrontage' and 'BedroomAbvGr', as their distributions are close to normal.\n",
        "* **Median Imputation:** Recommended for 'GarageYrBlt', as this feature is close to being normally distributed but may be skewed by extreme values.\n",
        "* **Arbitrary Number Imputation:** Suitable for '2ndFlrSF' and 'MasVnrArea', as the mojority of values equal 0 the missing values can be reasonably imputed with 0, based on the assumption that the absence of data indicates the absence of a second floor or masonry veneer area.\n",
        "* **Categorical Imputation:** Necessary for 'GarageFinish' and 'BsmtFinType1', as these are categorical variables that require a different imputation approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To clean the data and assess the effects of the cleaning we use the custom 'DataCleaningEffect()' function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code from Code Insititute's Feature Engine module\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
        "  \"\"\"\n",
        "  Function to visualize data cleaning effect\n",
        "  \"\"\"\n",
        "  flag_count=1 # Indicate plot number\n",
        "  \n",
        "  # distinguish between numerical and categorical variables\n",
        "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
        "\n",
        "  # scan over variables, \n",
        "    # first on variables that you applied the method\n",
        "    # if the variable is a numerical plot, a histogram if categorical plot a barplot\n",
        "  for set_of_variables in [variables_applied_with_method]:\n",
        "    print(\"\\n=====================================================================================\")\n",
        "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
        "    print(f\"{set_of_variables} \\n\\n\")\n",
        "  \n",
        "\n",
        "    for var in set_of_variables:\n",
        "      if var in categorical_variables:  # it is categorical variable: barplot\n",
        "        \n",
        "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
        "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
        "        dfAux = pd.concat([df1, df2], axis=0)\n",
        "        fig , axes = plt.subplots(figsize=(15, 5))\n",
        "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.legend() \n",
        "\n",
        "      else: # it is numerical variable: histogram\n",
        "\n",
        "        fig , axes = plt.subplots(figsize=(10, 5))\n",
        "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
        "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.legend() \n",
        "\n",
        "      plt.show()\n",
        "      flag_count+= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Drop Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variables to drop: ['EnclosedPorch', 'WoodDeckSF']\n",
        "* We create a separate data frame applying the imputation method\n",
        "* We assess the effect of the data imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "\n",
        "variables_method = ['EnclosedPorch', 'WoodDeckSF']\n",
        "variables_method\n",
        "\n",
        "imputer = DropFeatures(features_to_drop=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "df_method.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mean Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variables to impute the mean: ['LotFrontage' , 'BedroomAbvGr']\n",
        "* We create a separate data frame applying the imputation method\n",
        "* We assess the effect of the data imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import MeanMedianImputer\n",
        "\n",
        "variables_method = ['LotFrontage' , 'BedroomAbvGr']\n",
        "variables_method\n",
        "\n",
        "imputer = MeanMedianImputer(imputation_method='mean', variables=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Median Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variables to impute the median: ['2ndFlrSF' , 'GarageYrBlt', 'MasVnrArea']\n",
        "* We create a separate data frame applying the imputation method\n",
        "* We assess the effect of the data imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "\n",
        "variables_method = ['GarageYrBlt']\n",
        "variables_method\n",
        "\n",
        "imputer = MeanMedianImputer(imputation_method='median', variables=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arbitrary Number Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variables to impute the arbitrary number 0: ['2ndFlrSF', 'MasVnrArea']\n",
        "* We create a separate data frame applying the imputation method\n",
        "* We assess the effect of the data imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import ArbitraryNumberImputer\n",
        "\n",
        "variables_method = ['2ndFlrSF', 'MasVnrArea']\n",
        "\n",
        "imputer = ArbitraryNumberImputer(arbitrary_number=0, variables=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variables to impute the category: ['BsmtFinType1', 'GarageFinish']\n",
        "* We create a separate data frame applying the imputation method\n",
        "* We assess the effect of the data imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import CategoricalImputer\n",
        "\n",
        "variables_method = ['BsmtFinType1', 'GarageFinish']\n",
        "variables_method\n",
        "\n",
        "imputer = CategoricalImputer(imputation_method='missing', fill_value='Unf', variables=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train and Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We split our data into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['SalePrice'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use the Train set to learn and then apply the imputation methods to both sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop Variables ['EnclosedPorch', 'WoodDeckSF']\n",
        "variables_drop = ['EnclosedPorch', 'WoodDeckSF']\n",
        "imputer = DropFeatures(features_to_drop=variables_drop)\n",
        "imputer.fit(TrainSet)\n",
        "TrainSet, TestSet = imputer.transform(TrainSet), imputer.transform(TestSet)\n",
        "\n",
        "# MeanMedianImputer \n",
        "variables_mean = ['LotFrontage' , 'BedroomAbvGr']\n",
        "imputer = MeanMedianImputer(imputation_method='mean', variables=variables_mean)\n",
        "imputer.fit(TrainSet)\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)\n",
        "\n",
        "# MeanMedianImputer\n",
        "variable_median = ['GarageYrBlt']\n",
        "imputer = MeanMedianImputer(imputation_method='median', variables=variable_median)\n",
        "imputer.fit(TrainSet)\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)\n",
        "\n",
        "# ArbitraryNumberImputer \n",
        "variables_arbitrary = ['2ndFlrSF','MasVnrArea']\n",
        "imputer = ArbitraryNumberImputer(arbitrary_number=0, variables=variables_arbitrary)\n",
        "imputer.fit(TrainSet)\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)\n",
        "\n",
        "# CategoricalImputer\n",
        "variables_categorical = ['BsmtFinType1', 'GarageFinish']\n",
        "imputer = CategoricalImputer(imputation_method='missing', fill_value='Unf', variables=variables_categorical)\n",
        "imputer.fit(TrainSet)\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check for missing data again, to ensure we have effectivly handled all missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_missing_data = EvaluateMissingData(TrainSet)\n",
        "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
        "df_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "data_cleaning_pipeline = Pipeline([\n",
        "      ( 'drop',  DropFeatures(features_to_drop=['EnclosedPorch', 'WoodDeckSF']) ),\n",
        "      ( 'mean',  MeanMedianImputer(imputation_method='mean',\n",
        "                                     variables=['LotFrontage' , 'BedroomAbvGr']) ),\n",
        "      ( 'median',  MeanMedianImputer(imputation_method='median',\n",
        "                                     variables=['GarageYrBlt']) ),\n",
        "      ( 'arbitrary', ArbitraryNumberImputer(arbitrary_number=0,\n",
        "                                     variables=['2ndFlrSF','MasVnrArea']) ),\n",
        "      ( 'categorical',  CategoricalImputer(imputation_method='missing',\n",
        "                                     fill_value='Unf',\n",
        "                                     variables=['GarageFinish' , 'BsmtFinType1']) )\n",
        "])\n",
        "\n",
        "df = data_cleaning_pipeline.fit_transform(df)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # create here your folder\n",
        "  os.makedirs(name='outputs/datasets/cleaned')\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "# Save the Train Set\n",
        "TrainSet.to_csv(\"outputs/datasets/cleaned/train_set_cleaned.csv\", index=False)\n",
        "\n",
        "# Save the Test Set\n",
        "TestSet.to_csv(\"outputs/datasets/cleaned/test_set_cleaned.csv\", index=False)\n",
        "\n",
        "# Save the cleaned Dataset\n",
        "df.to_csv(\"outputs/datasets/cleaned/house_prices_cleaned.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
