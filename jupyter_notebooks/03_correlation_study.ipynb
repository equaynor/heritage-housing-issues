{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Correlation Study Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part of CRISP-DM **Data Understanding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Investigate the relationship between house attributes and sale price to address business requirement 1.\n",
        "\n",
        "## Approach\n",
        "\n",
        "* Perform exploratory data analysis using a ProfileReport to understand the distribution of variables and identify correlations.\n",
        "* Conduct correlation and Predictive Power Score (PPS) analysis to quantify the relationships between variables.\n",
        "* Create informative plots to visualize the correlations and facilitate understanding.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Cleaned dataset: outputs/datasets/cleaned/house_prices_cleaned.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Correlation plots and analysis that can be used to build the Streamlit App and provide insights into the relationships between house attributes and sale price.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Cleaned Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"outputs/datasets/cleaned/house_prices_cleaned.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we want to get familiar with the dataset. Using ProfileReport we can look at the variable types, distribution, missing data levels, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df, minimal=True)\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above report reveals that\n",
        "\n",
        "* 9 features have missing values.\n",
        "* EnclosedPorch and WoodDeckSF have 90.7% and 89.4% missing values respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To prepare our dataset for correlation analysis, we need to encode the categorical variables. This involves converting the categorical variables into numerical variables that can be used to calculate correlation coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.encoding import OneHotEncoder\n",
        "encoder = OneHotEncoder(variables=df.columns[df.dtypes=='object'].to_list(), drop_last=False)\n",
        "df_ohe = encoder.fit_transform(df)\n",
        "print(df_ohe.shape)\n",
        "df_ohe.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After encoding the categorical variables, our dataset now has 37 columns, including the original variables and the new encoded columns. We can now proceed with calculating the correlations and creating heatmaps to visualize the relationships between the variables.\n",
        "\n",
        "In the following cell we define several functions to calculate the correlations, create heatmaps, and display the results. These functions will also save the heatmaps to a folder for later use in the documentation of this project.\n",
        "\n",
        "Our goal is to analyze how the target variable for our machine learning models is correlated with other variables, including features and the target. We also want to examine multi-colinearity, which refers to the correlation between features themselves.\n",
        "\n",
        "We use the Spearman correlation coefficient to evaluate the monotonic relationship between variables, and the Pearson correlation coefficient to evaluate the linear relationship between two continuous variables. Additionally, we use the Power Predictive Score (PPS) to detect linear or non-linear relationships between two columns.\n",
        "\n",
        "We create heatmaps to visualize the correlations and PPS scores, and save them to a folder for later use. The heatmaps provide a clear and concise way to visualize the relationships between the variables and identify areas of high correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import ppscore as pps\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "  \"\"\"\n",
        "  Function to create heatmap using correlations.\n",
        "  \"\"\"\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "     # Save heatmaps to docs folder\n",
        "    if df.name == \"corr_spearman\":\n",
        "      try:\n",
        "        # create here your folder\n",
        "        os.makedirs(name='docs/plots')\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "      plt.savefig(f'docs/plots/heatmap_corr_spearman.png', bbox_inches='tight')\n",
        "    else:\n",
        "      try:\n",
        "        # create here your folder\n",
        "        os.makedirs(name='docs/plots')\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "      plt.savefig(f'docs/plots/heatmap_corr_pearson.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "    \"\"\"\n",
        "    Function to create heatmap using pps.\n",
        "    \"\"\"\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05,linecolor='grey')\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      # Save heatmap to docs folder\n",
        "      plt.savefig(f'docs/plots/heatmap_pps.png', bbox_inches='tight')\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  \"\"\"\n",
        "  Function to calculate correlations and pps.\n",
        "  \"\"\"\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_spearman.name = 'corr_spearman'\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "  df_corr_pearson.name = 'corr_pearson'\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "  \"\"\"\n",
        "  Function to display the correlations and pps.\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use CalculateCorrAndPPS function to calculate Correlations and Predictive Power Score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
        "                  figsize=(12,10), font_annot=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variables to Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now calculate and list the highest correlation values for our target variable ['SalePrice]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = df_ohe.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_spearman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.bar(x=corr_spearman[:5].index, height=corr_spearman[:5])\n",
        "plt.title(\"Spearman Correlation\", fontsize=20, y=1.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df_ohe.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.bar(x=corr_pearson[:5].index, height=corr_pearson[:5])\n",
        "plt.title(\"Pearson Correlation\", fontsize=20, y=1.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We merge the results of both correlation methods and choose the variables with coefficient scores of 0.5 and above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 8\n",
        "vars_to_study = set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list())\n",
        "vars_to_study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EDA of chosen variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda = df_ohe.filter(list(vars_to_study) + ['SalePrice'])\n",
        "df_eda.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting Against Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Target Variable Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We take a look at the range and distribution of our target ['SalePrice]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_style('whitegrid')\n",
        "target_var = 'SalePrice'\n",
        "\n",
        "def plot_target_hist(df, target_var):\n",
        "  \"\"\"\n",
        "  Function to plot a histogram of the target and\n",
        "  save the figure to folder.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(12, 5))\n",
        "  sns.histplot(data=df, x=target_var, kde=True)\n",
        "  plt.title(f\"Distribution of {target_var}\", fontsize=20)\n",
        "  # plt.savefig(f'docs/plots/hist_plot_{target_var}.png', bbox_inches='tight')        \n",
        "  plt.show()\n",
        "\n",
        "plot_target_hist(df, target_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now analyse the correlations of our chosen variables with our target visually. (Business Requirement 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_var = 'SalePrice'\n",
        "time = ['YearBuilt', 'YearRemodAdd']\n",
        "\n",
        "def corr_line_plot(df, col, target_var):\n",
        "  \"\"\"\n",
        "  Line plots of target variable vs time variables (years)\n",
        "  Figures are saved to folder.\n",
        "  \"\"\"\n",
        "  fig, axes = plt.subplots(figsize=(10, 5))\n",
        "  sns.lineplot(data=df, x=col, y=target_var)\n",
        "  plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "  plt.savefig(f'docs/plots/line_plot_price_by_{col}.png', bbox_inches='tight')        \n",
        "  plt.show()\n",
        "\n",
        "def corr_box_plot(df, col, target_var):\n",
        "  \"\"\"\n",
        "  Box plots of target variable vs categorical variables\n",
        "  Figures are saved to folder.\n",
        "  \"\"\"\n",
        "  fig, axes = plt.subplots(figsize=(10, 5))\n",
        "  sns.boxplot(data=df, x=col, y=target_var) \n",
        "  plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "  plt.savefig(f'docs/plots/box_plot_price_by_{col}', bbox_inches='tight')\n",
        "  plt.show()\n",
        "\n",
        "def corr_lm_plot(df, col, target_var):\n",
        "  \"\"\"\n",
        "  Linear regression plots of target variable vs continuous features\"\n",
        "  Figures are saved to folder.\n",
        "  \"\"\"\n",
        "  sns.lmplot(data=df, x=col, y=target_var, height=6, aspect=1.5)\n",
        "  plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "  plt.savefig(f'docs/plots/lm_plot_price_by_{col}.png', bbox_inches='tight')        \n",
        "  plt.show()\n",
        "\n",
        "\n",
        "for col in vars_to_study:\n",
        "  if len(df_eda[col].unique()) <= 10:\n",
        "    corr_box_plot(df_eda, col, target_var)\n",
        "    print(\"\\n\\n\")\n",
        "  else:\n",
        "    if col in time:\n",
        "      corr_line_plot(df_eda, col, target_var)\n",
        "      print(\"\\n\\n\")\n",
        "    else:\n",
        "      corr_lm_plot(df_eda, col, target_var)\n",
        "      print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also look at all chosen variables vs. sale prices in relation to the overall quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correlation_to_sale_price_scat(df, vars_to_study):\n",
        "    \"\"\"  scatterplots of variables vs SalePrice \"\"\"\n",
        "    target_var = 'SalePrice'\n",
        "    for col in vars_to_study:\n",
        "        fig, axes = plt.subplots(figsize=(10, 5))\n",
        "        axes = sns.scatterplot(data=df, x=col, y=target_var, hue='OverallQual')\n",
        "        plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "        plt.show()\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "correlation_to_sale_price_scat(df_eda, vars_to_study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our analysis reveals that:\n",
        "\n",
        "* Larger properties tend to have higher sale prices. (Size Hypothesis)\n",
        "    * Related variables: ['1stFlrSF', 'GarageArea', 'GrLivArea', 'TotalBsmtSF']\n",
        "* Higher quality ratings are associated with higher sale prices.\n",
        "    * Related variables: ['KitchenQual_TA', 'OverallQual']\n",
        "* Recently built houses and those with recent renovations tend to have higher sale prices.\n",
        "    * Related variables: [ 'YearBuilt', 'YearRemodAdd']\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
